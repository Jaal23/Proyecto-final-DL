# К Clasificaci贸n Taxon贸mica de Prote铆nas con Deep Learning


 Descripci贸n General
Este proyecto explora y compara diferentes arquitecturas de Deep Learning para resolver un problema fundamental en la bioinform谩tica: predecir el origen taxon贸mico (especie) de una prote铆na bas谩ndose 煤nicamente en su secuencia primaria de amino谩cidos.
El estudio se centra en el desaf铆o de modelar datos secuenciales biol贸gicos de longitud variable, contrastando enfoques de Visi贸n Artificial (CNN) contra enfoques de Procesamiento de Lenguaje Natural (RNN y Transformers).
El proyecto utiliza un subconjunto del dataset del desaf铆o CAFA 6 Protein Function Prediction.
 Objetivos del Proyecto
 * Comparaci贸n de Arquitecturas: Evaluar el rendimiento de modelos convolucionales (ResNet) versus modelos secuenciales (GRU, LSTM, Transformer) en datos biol贸gicos.
 * Ingenier铆a de Caracter铆sticas: Implementar t茅cnicas de Embedding aprendible frente a codificaci贸n One-Hot y proyecciones espaciales.
 * Robustez Metodol贸gica: Identificar y solucionar problemas de Fuga de Datos (Data Leakage) mediante estrategias de split estratificado.
 Dataset y Preprocesamiento
Los datos provienen de secuencias curadas de UniProtKB (Swiss-Prot).
 * Entrada (X): Secuencias de amino谩cidos (Archivos FASTA).
 * Salida (Y): Identificadores de Tax贸n (Archivos TSV).

El repositorio contiene la implementaci贸n de tres paradigmas distintos:
1.  Turbo GRU 
 * Tipo: Red Neuronal Recurrente.
 * Arquitectura: Capa de Embedding + GRU Bidireccional + Dropout.
 * Justificaci贸n: Captura dependencias secuenciales de largo alcance y el contexto global (N-terminal \leftrightarrow C-terminal) de manera eficiente.
 * Archivo: Turbo_GRU.py
2.  Transformer "From Scratch" 
 * Tipo: Mecanismo de Atenci贸n.
 * Arquitectura: Positional Embedding + Multi-Head Attention + Feed Forward Network.
 * Optimizador: AdamW con Cosine Decay Scheduler.
 * Justificaci贸n: Permite modelar interacciones entre amino谩cidos distantes sin las limitaciones de memoria de las RNNs.
 * Archivo: Transformer_Genomica.py
3.  ResNet-50 (L铆nea Base Experimental)
 * Tipo: Red Neuronal Convolucional (CNN).
 * Metodolog铆a: Adaptaci贸n forzada de secuencias 1D a "Pseudo-Im谩genes" 3D.
 * Resultado: Se utiliz贸 para demostrar que los enfoques de visi贸n pura no son ideales para datos secuenciales biol贸gicos sin representaciones espaciales reales.
 * Archivo: ResNet_Genomica.py

 * Implementaci贸n de Transfer Learning utilizando LLMs biol贸gicos pre-entrenados como ProtBERT o ESM-2 para superar la barrera del 50% de precisi贸n.
 * Expansi贸n del dataset para incluir m谩s clases taxon贸micas.
Autor: Javier Alejandro Mart铆nez Labra
